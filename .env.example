### Environment Configuration ###

# Simply change the values according to your needs and run the setup-env.sh
# script to apply the changes to the respective .env files.

# URL for the client application (used for frontend routing)
CLIENT_URL=http://localhost:3000

### Generative AI Configuration ###

# Endpoint URL for the LLM API (used by GenAI microservice)
LLM_API_URL=https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite-preview-06-17:generateContent
# Model name for the LLM (e.g., Gemini, GPT)
LLM_MODEL=gemini-2.5-flash-lite-preview-06-17
# Backend provider for LLM (e.g., google, openai, local)
LLM_BACKEND=google

# Internal URL for the course management service (used for service-to-service communication)
COURSEMGMT_URL=http://coursemgmt-service:8080

# ONLY for Google Gemini, else remove this variable:
# Enable or disable file parsing feature
FILE_PARSING=False